# Akbank Derin Ã–ÄŸrenme Bootcamp Projesi

Bu proje, Akbank Derin Ã–ÄŸrenme Bootcamp kapsamÄ±nda, TensorFlow ve Keras kÃ¼tÃ¼phaneleri kullanÄ±larak geliÅŸtirilen bir **EvriÅŸimli Sinir AÄŸÄ± (CNN)** modelini iÃ§ermektedir.  
Projenin temel amacÄ±, verilen bir gÃ¶rÃ¼ntÃ¼nÃ¼n yÃ¼ksek doÄŸrulukla **kedi mi yoksa kÃ¶pek mi** olduÄŸunu sÄ±nÄ±flandÄ±rmaktÄ±r.

---

##  Projenin AmacÄ± ve Hedefleri

- Kedi ve kÃ¶pek resimlerinden oluÅŸan geniÅŸ bir veri seti Ã¼zerinde bir CNN modeli eÄŸitmek.  
- Veri artÄ±rma (data augmentation) tekniklerini kullanarak modelin ezberlemesini (overfitting) Ã¶nlemek ve genelleme yeteneÄŸini artÄ±rmak.  
- EÄŸitilen modelin performansÄ±nÄ± doÄŸruluk (accuracy) ve kayÄ±p (loss) metrikleri Ã¼zerinden deÄŸerlendirmek.

---

##  Veri KÃ¼mesi

PopÃ¼ler Kaggle "Cat and Dog" veri kÃ¼mesi kullanÄ±lmÄ±ÅŸtÄ±r.

| Dizinin AdÄ±         | AÃ§Ä±klama                                         |
|--------------------|-------------------------------------------------|
| EÄŸitim Verisi       | Modelin Ã¶ÄŸrenmesi iÃ§in kullanÄ±lan binlerce kedi ve kÃ¶pek gÃ¶rÃ¼ntÃ¼sÃ¼. |
| Test (DoÄŸrulama) Verisi | Modelin eÄŸitimde gÃ¶rmediÄŸi ve performansÄ±nÄ± Ã¶lÃ§mek iÃ§in kullanÄ±lan gÃ¶rÃ¼ntÃ¼ler. |

---

## ğŸ› ï¸ Uygulanan AdÄ±mlar ve Teknik Detaylar

### 1. Veri YÃ¼kleme ve Ã–n Ä°ÅŸleme
- `ImageDataGenerator` sÄ±nÄ±fÄ± kullanÄ±larak gÃ¶rÃ¼ntÃ¼ler dizinlerden okunmuÅŸtur.  
- TÃ¼m gÃ¶rÃ¼ntÃ¼ler, modelin giriÅŸ katmanÄ±na uygun olacak ÅŸekilde **128x128** piksel boyutuna yeniden Ã¶lÃ§eklendirilmiÅŸtir.  
- Piksel deÄŸerleri **0-1 aralÄ±ÄŸÄ±na** normalleÅŸtirilmiÅŸtir.

### 2. Veri ArtÄ±rma (Data Augmentation)
- Modelin genelleme yeteneÄŸini artÄ±rmak ve overfittingâ€™i Ã¶nlemek iÃ§in eÄŸitim verilerine rastgele dÃ¶nÃ¼ÅŸÃ¼mler uygulanmÄ±ÅŸtÄ±r:
  - `rotation_range`: GÃ¶rÃ¼ntÃ¼leri rastgele dÃ¶ndÃ¼rme  
  - `width_shift_range` / `height_shift_range`: Yatay ve dikey kaydÄ±rma  
  - `shear_range`: Makaslama (kÄ±rpma)  
  - `zoom_range`: Rastgele yakÄ±nlaÅŸtÄ±rma  
  - `horizontal_flip`: GÃ¶rÃ¼ntÃ¼leri yatay Ã§evirme

### 3. Model Mimarisi (CNN)
| Katman Tipi | Parametreler | Aktivasyon | AmaÃ§ |
|-------------|-------------|------------|------|
| Conv2D      | Ã‡eÅŸitli filtre sayÄ±larÄ± | relu | DÃ¼ÅŸÃ¼k ve orta seviyeli Ã¶zellikleri Ã§Ä±karma |
| MaxPooling2D | (2,2) | N/A | Boyut indirgeme ve Ã¶nemli Ã¶zellikleri koruma |
| Flatten     | N/A | N/A | 2D haritalarÄ± 1D vektÃ¶re dÃ¶nÃ¼ÅŸtÃ¼rme |
| Dense (Gizli) | Ã‡eÅŸitli nÃ¶ron sayÄ±larÄ± | relu | Ã–ÄŸrenilen Ã¶zellikleri harmanlama |
| Dense (Ã‡Ä±kÄ±ÅŸ) | 1 nÃ¶ron | sigmoid | Ä°kili sÄ±nÄ±flandÄ±rma Ã§Ä±ktÄ±sÄ± (0-1) |

### 4. Model Derleme ve EÄŸitimi
| Parametre | DeÄŸer | AÃ§Ä±klama |
|-----------|-------|----------|
| Optimizasyon | adam | HÄ±zlÄ± ve etkin optimizasyon |
| KayÄ±p Fonksiyonu | binary_crossentropy | Ä°kili sÄ±nÄ±flandÄ±rma problemleri iÃ§in standart kayÄ±p |
| Metrik | accuracy | Performans Ã¶lÃ§Ã¼mÃ¼ |
| Epoch | 10 | EÄŸitim veri setinin kaÃ§ kez gÃ¶rÃ¼leceÄŸi |
| EÄŸitim Fonksiyonu | fit_generator | Veri artÄ±rma ile eÄŸitim |

---

##  SonuÃ§lar ve DeÄŸerlendirme
- **DoÄŸruluk:** EÄŸitim sonunda model, doÄŸrulama verileri Ã¼zerinde yaklaÅŸÄ±k **%80 doÄŸruluk** saÄŸlamÄ±ÅŸtÄ±r.  
- **Grafiksel Analiz:** EÄŸitim/doÄŸrulama doÄŸruluk ve kayÄ±p grafikleri, modelin saÄŸlÄ±klÄ± bir Ã¶ÄŸrenme sÃ¼reci geÃ§irdiÄŸini ve overfittingâ€™in bÃ¼yÃ¼k Ã¶lÃ§Ã¼de Ã¶nlendiÄŸini gÃ¶stermektedir.  
- **Ã‡Ä±karÄ±m:** GeliÅŸtirilen CNN modeli, kedi ve kÃ¶pek gÃ¶rÃ¼ntÃ¼lerini baÅŸarÄ±lÄ± bir ÅŸekilde sÄ±nÄ±flandÄ±rmaktadÄ±r.

---

##  Gelecek Ä°yileÅŸtirmeler
- Epoch sayÄ±sÄ±nÄ± artÄ±rmak  
- Daha derin mimari kullanmak  
- Transfer Learning (VGG16, ResNet) ile performansÄ± artÄ±rmak  

---

##  Proje Linki 

[Upl{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":30378,"sourceType":"datasetVersion","datasetId":23777}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import kagglehub\n\n\npath = kagglehub.dataset_download(\"tongpython/cat-and-dog\")\n\nprint(\"Path to dataset files:\", path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T20:32:40.115607Z","iopub.execute_input":"2025-09-26T20:32:40.115990Z","iopub.status.idle":"2025-09-26T20:32:40.249721Z","shell.execute_reply.started":"2025-09-26T20:32:40.115958Z","shell.execute_reply":"2025-09-26T20:32:40.248562Z"}},"outputs":[{"name":"stdout","text":"Path to dataset files: /kaggle/input/cat-and-dog\n","output_type":"stream"}],"execution_count":267},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T20:32:40.251439Z","iopub.execute_input":"2025-09-26T20:32:40.252205Z","iopub.status.idle":"2025-09-26T20:32:40.257096Z","shell.execute_reply.started":"2025-09-26T20:32:40.252102Z","shell.execute_reply":"2025-09-26T20:32:40.256009Z"}},"outputs":[],"execution_count":268},{"cell_type":"code","source":"train_gen = train_datagen.flow_from_directory(\n    train_dir,               \n    target_size=(128,128),   \n    batch_size=32,\n    subset='training',      \n    class_mode='binary'     \n)\n\nval_gen = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=(128,128),\n    batch_size=32,\n    subset='validation',     \n    class_mode='binary', \n    shuffle= False\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T20:32:40.258325Z","iopub.execute_input":"2025-09-26T20:32:40.258621Z","iopub.status.idle":"2025-09-26T20:32:40.468670Z","shell.execute_reply.started":"2025-09-26T20:32:40.258595Z","shell.execute_reply":"2025-09-26T20:32:40.467558Z"}},"outputs":[{"name":"stdout","text":"Found 6404 images belonging to 2 classes.\nFound 1601 images belonging to 2 classes.\n","output_type":"stream"}],"execution_count":269},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport numpy as np\nimport os\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T20:32:40.471324Z","iopub.execute_input":"2025-09-26T20:32:40.472321Z","iopub.status.idle":"2025-09-26T20:32:40.478621Z","shell.execute_reply.started":"2025-09-26T20:32:40.472290Z","shell.execute_reply":"2025-09-26T20:32:40.477395Z"}},"outputs":[],"execution_count":270},{"cell_type":"code","source":"\ntrain_dir = \"/kaggle/input/cat-and-dog/training_set\"\ntest_dir = \"/kaggle/input/cat-and-dog/test_set\"\n\n\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,\n    validation_split=0.2,   \n    rotation_range=20,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    zoom_range=0.2,\n    horizontal_flip=True\n)\n\n\ntrain_gen = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=(128,128),\n    batch_size=32,\n    subset='training',\n    class_mode='binary'\n)\n\n\nval_gen = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=(128,128),\n    batch_size=32,\n    subset='validation',\n    class_mode='binary'\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T20:32:40.479630Z","iopub.execute_input":"2025-09-26T20:32:40.480193Z","iopub.status.idle":"2025-09-26T20:32:40.680180Z","shell.execute_reply.started":"2025-09-26T20:32:40.480159Z","shell.execute_reply":"2025-09-26T20:32:40.679189Z"}},"outputs":[{"name":"stdout","text":"Found 6404 images belonging to 1 classes.\nFound 1601 images belonging to 1 classes.\n","output_type":"stream"}],"execution_count":271},{"cell_type":"code","source":"# CNN Modeli\nmodel = models.Sequential([\n    layers.Conv2D(32, (3,3), activation='relu', input_shape=(128,128,3)),\n    layers.MaxPooling2D(2,2),\n    \n    layers.Conv2D(64, (3,3), activation='relu'),\n    layers.MaxPooling2D(2,2),\n    \n    layers.Conv2D(128, (3,3), activation='relu'),\n    layers.MaxPooling2D(2,2),\n    \n    layers.Flatten(),\n    layers.Dense(128, activation='relu'),\n    layers.Dropout(0.5),\n    layers.Dense(1, activation='sigmoid')  \n])\n\n# Modeli compile et\nmodel.compile(optimizer='adam',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T20:32:40.681328Z","iopub.execute_input":"2025-09-26T20:32:40.681601Z","iopub.status.idle":"2025-09-26T20:32:40.773419Z","shell.execute_reply.started":"2025-09-26T20:32:40.681578Z","shell.execute_reply":"2025-09-26T20:32:40.772102Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"}],"execution_count":272},{"cell_type":"code","source":"\nprint(val_gen.class_indices)\nprint(val_gen.classes[:20])  \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T20:32:40.774488Z","iopub.execute_input":"2025-09-26T20:32:40.774772Z","iopub.status.idle":"2025-09-26T20:32:40.781643Z","shell.execute_reply.started":"2025-09-26T20:32:40.774751Z","shell.execute_reply":"2025-09-26T20:32:40.780149Z"}},"outputs":[{"name":"stdout","text":"{'training_set': 0}\n[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n","output_type":"stream"}],"execution_count":273},{"cell_type":"code","source":"import os\n\nbase_dir = \"/kaggle/input/cat-and-dog/training_set/training_set\"\nprint(os.listdir(base_dir)) \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T20:32:40.782605Z","iopub.execute_input":"2025-09-26T20:32:40.783652Z","iopub.status.idle":"2025-09-26T20:32:40.808922Z","shell.execute_reply.started":"2025-09-26T20:32:40.783617Z","shell.execute_reply":"2025-09-26T20:32:40.807190Z"}},"outputs":[{"name":"stdout","text":"['dogs', 'cats']\n","output_type":"stream"}],"execution_count":274},{"cell_type":"code","source":"import os\nimport shutil\n\nbase_dir = \"/kaggle/input/cat-and-dog/training_set\"\nnew_base = \"/kaggle/working/data\"  \n\nos.makedirs(new_base, exist_ok=True)\nos.makedirs(os.path.join(new_base, \"cat\"), exist_ok=True)\nos.makedirs(os.path.join(new_base, \"dog\"), exist_ok=True)\n\nfor file in os.listdir(base_dir):\n    if file.startswith(\"cat\"):\n        shutil.copy(os.path.join(base_dir, file), os.path.join(new_base, \"cat\"))\n    elif file.startswith(\"dog\"):\n        shutil.copy(os.path.join(base_dir, file), os.path.join(new_base, \"dog\"))\n\nprint(os.listdir(new_base))\nprint(len(os.listdir(os.path.join(new_base,\"cat\"))), len(os.listdir(os.path.join(new_base,\"dog\"))))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T20:32:40.810240Z","iopub.execute_input":"2025-09-26T20:32:40.810516Z","iopub.status.idle":"2025-09-26T20:32:40.835266Z","shell.execute_reply.started":"2025-09-26T20:32:40.810487Z","shell.execute_reply":"2025-09-26T20:32:40.834101Z"}},"outputs":[{"name":"stdout","text":"['cat', 'dog']\n0 0\n","output_type":"stream"}],"execution_count":275},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ntrain_dir = \"/kaggle/input/cat-and-dog/training_set/training_set\"  \ntest_dir = \"/kaggle/input/cat-and-dog/test_set/test_set\"          \n\n\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,\n    validation_split=0.2,  \n    rotation_range=20,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    zoom_range=0.2,\n    horizontal_flip=True\n)\n\n\ntrain_gen = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=(128,128),\n    batch_size=32,\n    class_mode='binary',\n    subset='training',\n    shuffle=True\n)\n\n\nval_gen = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=(128,128),\n    batch_size=32,\n    class_mode='binary',\n    subset='validation',\n    shuffle=False\n)\n\n\ntest_datagen = ImageDataGenerator(rescale=1./255)\ntest_gen = test_datagen.flow_from_directory(\n    test_dir,\n    target_size=(128,128),\n    batch_size=32,\n    class_mode='binary',\n    shuffle=False\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T20:32:40.838519Z","iopub.execute_input":"2025-09-26T20:32:40.838886Z","iopub.status.idle":"2025-09-26T20:32:41.326895Z","shell.execute_reply.started":"2025-09-26T20:32:40.838861Z","shell.execute_reply":"2025-09-26T20:32:41.325330Z"}},"outputs":[{"name":"stdout","text":"Found 6404 images belonging to 2 classes.\nFound 1601 images belonging to 2 classes.\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/394437131.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mtest_datagen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrescale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m test_gen = test_datagen.flow_from_directory(\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0mtest_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/preprocessing/image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m   1136\u001b[0m         \u001b[0mkeep_aspect_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m     ):\n\u001b[0;32m-> 1138\u001b[0;31m         return DirectoryIterator(\n\u001b[0m\u001b[1;32m   1139\u001b[0m             \u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/preprocessing/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[0mclasses_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 481\u001b[0;31m             \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    482\u001b[0m             \u001b[0mclasses_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilenames\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    627\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 629\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    630\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":276},{"cell_type":"code","source":"from tensorflow.keras import layers, Sequential\n\nmodel = models.Sequential([\n    layers.Input(shape=(128,128,3)),\n\n    layers.Conv2D(32, (3,3), activation='relu'),\n    layers.MaxPooling2D((2,2)),\n\n    layers.Conv2D(64, (3,3), activation='relu'),\n    layers.MaxPooling2D((2,2)),\n\n    layers.Conv2D(128, (3,3), activation='relu'),\n    layers.MaxPooling2D((2,2)),\n\n    layers.Flatten(),\n    layers.Dense(128, activation='relu'),\n    layers.Dropout(0.5),\n    layers.Dense(1, activation='sigmoid') \n\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nmodel.summary()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T20:32:41.327582Z","iopub.status.idle":"2025-09-26T20:32:41.327943Z","shell.execute_reply.started":"2025-09-26T20:32:41.327754Z","shell.execute_reply":"2025-09-26T20:32:41.327767Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"history = model.fit(\n    train_gen,\n    validation_data=val_gen,\n    epochs=5,  # dilersen 15-20 yapabilirsin\n    verbose=1\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T20:32:41.329972Z","iopub.status.idle":"2025-09-26T20:32:41.330287Z","shell.execute_reply.started":"2025-09-26T20:32:41.330135Z","shell.execute_reply":"2025-09-26T20:32:41.330145Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nmodel.save('/kaggle/working/sequential_1.h5')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T20:32:41.331610Z","iopub.status.idle":"2025-09-26T20:32:41.331969Z","shell.execute_reply.started":"2025-09-26T20:32:41.331780Z","shell.execute_reply":"2025-09-26T20:32:41.331793Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"history = model.fit(\n    train_gen,\n    validation_data=val_gen,\n    epochs=5,\n    verbose=1\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T20:32:41.335722Z","iopub.status.idle":"2025-09-26T20:32:41.336387Z","shell.execute_reply.started":"2025-09-26T20:32:41.336144Z","shell.execute_reply":"2025-09-26T20:32:41.336166Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n\nplt.figure(figsize=(12,5))\nplt.subplot(1,2,1)\nplt.plot(history.history['accuracy'], label='Train Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.title('Accuracy over epochs')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\n\n\nplt.subplot(1,2,2)\nplt.plot(history.history['loss'], label='Train Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.title('Loss over epochs')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T20:32:41.338077Z","iopub.status.idle":"2025-09-26T20:32:41.338559Z","shell.execute_reply.started":"2025-09-26T20:32:41.338312Z","shell.execute_reply":"2025-09-26T20:32:41.338332Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport seaborn as sns\n\n\ntest_gen.reset()\npreds = model.predict(test_gen, verbose=1)\ny_pred = np.where(preds>0.5, 1, 0)  # 0=cat, 1=dog\ny_true = test_gen.classes\n\n\ncm = confusion_matrix(y_true, y_pred)\nplt.figure(figsize=(6,5))\nsns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=list(test_gen.class_indices.keys()), yticklabels=list(test_gen.class_indices.keys()))\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.title(\"Confusion Matrix\")\nplt.show()\n\n\nprint(classification_report(y_true, y_pred, target_names=list(test_gen.class_indices.keys())))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T20:32:41.340088Z","iopub.status.idle":"2025-09-26T20:32:41.340439Z","shell.execute_reply.started":"2025-09-26T20:32:41.340269Z","shell.execute_reply":"2025-09-26T20:32:41.340291Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n\nplt.plot(history.history['accuracy'], label='Train Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.title('Model Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()\n\n\nplt.plot(history.history['loss'], label='Train Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.title('Model Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T20:32:41.341722Z","iopub.status.idle":"2025-09-26T20:32:41.342393Z","shell.execute_reply.started":"2025-09-26T20:32:41.341917Z","shell.execute_reply":"2025-09-26T20:32:41.341936Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ny_true = test_gen.classes  # gerÃ§ek labellar\ncm = confusion_matrix(y_true, y_pred)\n\n\ncmn = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\nplt.figure(figsize=(6,5))\nsns.heatmap(cmn, annot=True, fmt='.2f')\nplt.ylabel('Actual')\nplt.xlabel('Predicted')\nplt.title('Cats vs Dogs Confusion Matrix')\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T20:32:41.343709Z","iopub.status.idle":"2025-09-26T20:32:41.344103Z","shell.execute_reply.started":"2025-09-26T20:32:41.343945Z","shell.execute_reply":"2025-09-26T20:32:41.343958Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\n\n\ndummy_input = np.zeros((1, 128, 128, 3))\n\n\npred = model.predict(dummy_input)  # EÄŸer modelin adÄ± 'model' ise\nprint(pred)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T20:32:41.346217Z","iopub.status.idle":"2025-09-26T20:32:41.346614Z","shell.execute_reply.started":"2025-09-26T20:32:41.346466Z","shell.execute_reply":"2025-09-26T20:32:41.346482Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\nmodel = load_model('/kaggle/working/sequential_1.h5')\n\n\nclass_names = ['Cat', 'Dog']\n\n# ------------------------\n\n# ------------------------\ninput_shape = model.input_shape  # (None, 128, 128, 3)\ndummy_input = np.zeros((1, input_shape[1], input_shape[2], input_shape[3]))\ndummy_pred = model.predict(dummy_input)\ndummy_label = class_names[int(dummy_pred[0][0] > 0.5)]\nprint(\"Dummy input prediction:\", dummy_label)\n\nfrom tensorflow.keras.preprocessing import image\nimport numpy as np\n\n\nimg = image.load_img(img_path, target_size=(128,128))\nx = image.img_to_array(img)\nx = np.expand_dims(x, axis=0)  # batch dimension ekle\nx = x / 255.0                  # normalize et\n\n\npred = model.predict(x)\nlabel = 'Dog' if pred[0][0] > 0.5 else 'Cat'\nprint(\"Prediction:\", label)\n\nreal_pred = model.predict(x)\nreal_label = class_names[int(real_pred[0][0] > 0.5)]\nprint(\"Real image prediction:\", real_label)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T20:32:41.347920Z","iopub.status.idle":"2025-09-26T20:32:41.348271Z","shell.execute_reply.started":"2025-09-26T20:32:41.348125Z","shell.execute_reply":"2025-09-26T20:32:41.348138Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.preprocessing import image\nimport numpy as np\n\n\nimg = image.load_img(img_path, target_size=(128,128))\nx = image.img_to_array(img)\nx = np.expand_dims(x, axis=0) \nx = x / 255.0                 \n\n\nprediction = model.predict(x)  \n\n\npred_value = prediction[0][0]\n\n\nlabel = \"Dog\" if pred_value > 0.5 else \"Cat\"\n\nprint(f\"The model predicts: {label} (confidence: {pred_value:.2f})\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T20:32:41.350625Z","iopub.status.idle":"2025-09-26T20:32:41.351116Z","shell.execute_reply.started":"2025-09-26T20:32:41.350906Z","shell.execute_reply":"2025-09-26T20:32:41.350925Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n\nimg = load_img(\"/kaggle/input/cat-and-dog/test_set/test_set/dogs/dog.4002.jpg\", target_size=(150, 150))\n\nplt.imshow(img)\nplt.title(f\"Prediction: {label} ({pred_value:.2f})\")\nplt.axis('off')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T20:32:41.353700Z","iopub.status.idle":"2025-09-26T20:32:41.354160Z","shell.execute_reply.started":"2025-09-26T20:32:41.353969Z","shell.execute_reply":"2025-09-26T20:32:41.353993Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ny_pred = model.predict(test_gen, verbose=1)\n\n\ny_pred_labels = np.where(y_pred > 0.5, 1, 0)\n\n\ny_true = test_gen.classes\n\n\nfrom sklearn.metrics import classification_report, confusion_matrix\n\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_true, y_pred_labels, target_names=list(test_gen.class_indices.keys())))\n\nprint(\"\\nConfusion Matrix:\")\nprint(confusion_matrix(y_true, y_pred_labels))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T20:32:41.355908Z","iopub.status.idle":"2025-09-26T20:32:41.356304Z","shell.execute_reply.started":"2025-09-26T20:32:41.356101Z","shell.execute_reply":"2025-09-26T20:32:41.356121Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ntrain_acc = history.history['accuracy'][-1]\nval_acc = history.history['val_accuracy'][-1]\ntrain_loss = history.history['loss'][-1]\nval_loss = history.history['val_loss'][-1]\n\nprint(f\"EÄŸitim DoÄŸruluÄŸu: {train_acc:.4f}\")\nprint(f\"DoÄŸrulama DoÄŸruluÄŸu: {val_acc:.4f}\")\nprint(f\"EÄŸitim KayÄ±p: {train_loss:.4f}\")\nprint(f\"DoÄŸrulama KayÄ±p: {val_loss:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T20:32:41.357431Z","iopub.status.idle":"2025-09-26T20:32:41.357816Z","shell.execute_reply.started":"2025-09-26T20:32:41.357616Z","shell.execute_reply":"2025-09-26T20:32:41.357636Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn import tree\n\n\ntest_steps = test_gen.samples // test_gen.batch_size\ny_pred = model.predict(test_gen, steps=test_steps+1)\ny_pred_classes = (y_pred > 0.5).astype(int).reshape(-1)\ny_true = test_gen.classes[:len(y_pred_classes)]\n\n\nX_simple = y_pred  \nbest_tree = tree.DecisionTreeClassifier(max_depth=3, random_state=42)\nbest_tree.fit(X_simple, y_true)\n\n\nfig, ax = plt.subplots(figsize=(10,8), dpi=300)\ntree.plot_tree(\n    best_tree,\n    feature_names=['pred_proba'], \n    class_names=['Cat','Dog'],\n    filled=True,\n    rounded=True,\n    fontsize=10,\n    ax=ax\n)\nfig.savefig('dec_tree_simple.png', bbox_inches='tight')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T20:32:41.360575Z","iopub.status.idle":"2025-09-26T20:32:41.361181Z","shell.execute_reply.started":"2025-09-26T20:32:41.360806Z","shell.execute_reply":"2025-09-26T20:32:41.360844Z"}},"outputs":[],"execution_count":null}]}oading akbank-derin-renme-bootcamp-projesi (1).ipynbâ€¦]()
https://www.kaggle.com/code/azraaltundasss/akbank-derin-renme-bootcamp-projesi 

##  Gereksinimler
Python 3.x ve aÅŸaÄŸÄ±daki kÃ¼tÃ¼phaneler gereklidir:  

```txt
tensorflow
keras
numpy
matplotlib
pandas
opencv-python


